An SRE's Guide to Distributed Consensus
7 Nov 2020
Tags: Distributed Systems, Distributed Consensus, Raft, Site Reliability Engineering, DevOps
Summary: An introduction to distributed consensus and its applications in the DevOps world.

Jason Rogena
Site Reliability Engineer, Ona
jason@rogena.me
https://rogena.me
@jrogena

: Hi. My Name is Jason and I'll be giving a presentation on distributed consensus and its applications in the DevOps world.
: I titled the presentation An SRE's Guide to Distributed Consensus. Spoiler alert, there is no mention of the number 42.
: OK. Let's get started.

* Consensus

Some situations in computing require components of a system to come to an agreement (or general agreement)

.image media/consensus.jpg

: I'll begin by defining what consensus means.
: Consensus is when a group of individuals comes to an agreement, or a general agreement.
: A general agreement implies that not all individuals in the group need to agree with the decision. As long as most of the individuals have agreed
: then we can assume that a general consensus was achieved.
: There are several applications for consensus in computing.
: As an example, if you have several workers that can process queued tasks, the workers will need to reach a consensus on which of them should process
: a task in the queue to prevent situations where more than one worker processes the same task.
: This can be achieved by assigning a lock to each task on the queue. The workers then agreed that whichever worker acquires a task's lock first will
: be responsible for processing that task.
: Consensus in synchronized systems, like the one I have just mentioned, is more often than not, a trivial problem and can be achieved using
: locks (which are also called mutexes) and semaphores.

* Consensus

Interesting problem in distributed systems where components are independent, likely connected to each other over the network, and prone to failure.

.image media/distributed-systems-failure.jpg

: However, consensus in distributed systems is a non-trivial problem due to the nature of distributed systems.
: Distributed systems are generally assumed to contain independent components (which I'll call nodes) that are connected to each other over the network.
: It is expected that both the nodes and the network connecting the nodes are prone to failure.
: The big consensus problem in distributed systems then is; "How to achieve consensus when some of the nodes that are expected to
: agree on something aren't all reachable at the same time but are likely to be reachable at some point in time".

* Distributed Consensus

Several distributed consensus algorithms available and work despite possibility for:

1. Temporary and permanent failure of nodes
2. Varying network latency and the possibility of network partitions
3. Node asynchronicity

.image media/paxos-island.jpg

: Because consensus in distributed systems is not a trivial problem to solve, several algorithms have been created to tackle it.
: Most of these algorithms assume that nodes in a distributed system may fail temporarily or permanently.
: They also assume that the network connecting the nodes can have varying latencies and that there is a possibility of network partitions (this is where
: different sections in a network are unable to reach each other for some time).
: The algorithms also assume that nodes in a distributed system might have varying computing power and varying system clocks.
: You, for example, can have two nodes, A and B, in a distributed system where A is a beefy server and B is a not-so-beefy laptop. A's system clock might
: be synchronized with an NTP server and B's system clock might not be synchronized with anything at all, and therefore is likely not be accurate.
: "What example distributed consensus algorithms exist?", you may ask. Before I answer this question, I'll tell a short story that hopefully will explain a bit why
: the distributes consensus landscape is what it is today.
: In 1984, Leslie Lamport (some of us might know him as the the initial developer of LaTeX), in a paper titled "Using Time Instead of Timeout for Fault-Tolerant
: Distributed Systems", defined an approach of solving the distributed consensus problem which he called the state machine replication approach.
: In the next slide, I'll try expound a bit more on what state machines are and what state machine replication entails. Let me finish the short story first.
: In 1989, Lamport came up with the Paxos protocol for distributed consensus. Paxos relies on the state machine replication approach he had presented in 1984.
: It turns out that several of the most popular distributed consensus algorithms today fall under the Paxos family and maintain some aspects of the original protocol.
: It's also important for me to state that several other popular, non-Paxos, distributed consensus algorithms also follow the state machine replication approach.
: Fun fact: Paxos is named after the Greek island Paxos. This isn't random really. Lamport, in his 1984 paper, explained the state machine replication approach
: using an analogy of a fictitious parliament on the island of Paxos that had to function "even though legislators continually wandered in and out of the 
: parliamentary Chamber".
: The picture on this side is one of the island of Paxos. Looks nice, right?!

* State Machine?

Something which when fed a command, changes from one discrete state to another. Examples include, a:

1. database
2. video game
3. switch

.image media/state-machine.png

: So... What is a state machine?
: A state machine is something which when fed a command, changes from one discrete state to another.
: A good example of a state machine is a database, which if you feed a query, might change from one state to another.
: If you, for instance, run an insert query against a database, the database will change from a state where it didn't have the data inserted using the query
: to a state where it has this data. In this example, the database is the state machine, and the insert query is a command that changes the database from
: one state to another.
: Another example of a state machine is a video game. When you feed a video game commands through an input device, like a game pad, the video game changes 
: from a state where, for instance, a character is standing to a state where the character is seated.
: A simpler example of a state machine is a light bulb. When you flip the light bulb's switch up, the bulb transitions from a state where it was off to a state where it
: is on. When you flip the switch down, the light bulb transitions from a state where it was on to a state where it is off. The act of flipping the switch up or down is
: the command, in this example and the light bulb (who's state is affected by commands applied on it) is the state machine.
: The image on this slide is what is called a state machine diagram. It's used to show the different discrete states a state machine can be in as circles. The directional
: lines connecting the circles represent the commands that transition the state machine from one of its discrete states to another.
: An important characteristic of state machines is, if you feed the machine a sequence of commands, you will always end up in the same state if the number and order
: of commands is maintained.
: State machine replication involves sharing commands (intended to be applied to state machines) in a manner that preserves the number and order of these commands.
: The assumption is that if, for instance, commands are shared amongst 10 individuals, each in possession of the same kind of state machine, after each of the individuals
: has applied the shared commands on their state machines, all the state machines will be in the exact same state.
: In the state machine replication approach, consensus is achieved when a majority of the nodes agree on the commands to apply against their individual state machines and
: in what order these commands should be applied.

* Raft

One of the more popular distributed consensus algorithms. Considered more understandable than Paxos.

.image media/raft-replicated-state-machine-model.png

: I have touched on some of the principles behind distributed consensus algorithms. I have also mentioned that Paxos is one of the popular distributed consensus algorithms.
: I am now going to narrow down on one distributed consensus algorithm and talk about how it works. It will not be Paxos though.
: The algorithm I'm going to talk about is Raft. Raft, just like Paxos, is one of the more popular distributed consensus algorithms. It is, however, considered easier to understand.
: Several popular distributed data stores, including Consul by Hashicorp and etcd (which is the default storage layer in Kubernetes clusters), use Raft for distributed consensus.
: Most recently, Apache Kafka switched from Zookeeper to internal code, that uses Raft, for consensus.
: The diagram on this side illustrates the architecture of a distributed system using Raft. It's a client-server architecture with clients sending commands to the servers.
: The servers are technically the distributed system's nodes. Each of the servers contains the consensus module (which is the code implementing the Raft algorithm).
: Each of the servers also contains a log which is just an ordered list of commands as they are received from the clients. 
: And each of the servers also has a state machine. Commands in the log are applied against the state machine in the order they appear.
: OK... If this was a distributed PostgreSQL database, the commands sent from clients would be the SQL queries, and the state machines would be PostgreSQL databases these queries are
: ran against. Each of the nodes would have its own independent PostgreSQL database.
: Each of the nodes would also have its own independent log which is where SQL queries are stored before they are ran against the PostgreSQL database.
: Notice from the diagram that Raft follows Lamport's state machine replication approach.

* Raft 

Broken down into three parts:

1. Leader election
2. Log replication
3. Safety

.image media/raft.png

.link http://thesecretlivesofdata.com/raft/ http://thesecretlivesofdata.com/raft/

: So... how does Raft work? The Raft algorithm is broken down into three parts. The first part is leader election where the nodes in a cluster elect one of them
: to be their leader. The second part is log replication which handles how commands are gotten from the clients, sent to the nodes in the distributed system,
: and finally safely applied to their state machines.
: The third part (called safety) deals with how to handle certain edge cases during leader election and log replication.
: Don't worry. The role of the leader in Raft will become clear when I explain how log replication works.
: For the purposes of this presentation, I will only focus on explaining a bit of how leader election and log replication work in Raft.
: I will, however, not cover anything on safety.
: I highly encourage you to visit the link on this slide for a visual explanation of how Raft handles leader election, log replication, and safety.

* Leader Election

.html raft-visualization.html

: OK... Let's talk about leader election.
: Before going through the visualization on this slide, I'll try and explain how leader election works.
: In one of the previous sides, I explained the architecture of a distributed system in Raft where each of the nodes is expected to have a log and a state machine. 
: Apart from each node having a log and a state machine, they also have an integer counter called a term. This counter is what is used to distinguish a past leader
: from a current leader. Each of the nodes have the initial value of their term set to 1.
: Nodes in the cluster can be in one of three states at any one particular time; they can either be a leader, a candidate, or a follower.
: When a node joins the cluster, it joins as a follower. The first thing it does is start a count down (called an election timeout) which lasts an arbitrary number of
: milliseconds. Each node controls how long its election timeout should last.
: If the election timeout expires before the leader of the cluster sends a message to it, the nodes starts an election.
: To start an election, a node changes its state to candidate, it then increments its term by one, votes for itself, then sends a request to all of the nodes in the
: cluster asking for their vote.
: When a node receives an election request from a candidate in the cluster, it evaluates whether it should vote for the candidate. One of the conditions it checks is whether the
: candidate's term is greater than its own. It will only vote for the the candidate if this is true. If all the conditions are met, the node changes its term to that of the candidate
: then sends its vote back to the candidate.
: When a candidate receives a vote from a node, it evaluates whether the total number of votes it has gotten so far in its current term is 50% of all nodes plus 1. If so,
: it sends out a request to all the nodes (including those that didn't vote for it) indicating that it is now the leader for the term.
: Even after a leader is gotten or discovered, every follower and candidate continues to run their election timeout. They reset the timeout whenever they receive a message from the
: leader. This is done so that a node can be able to discover when the leader is unavailable so that it can start a new election to become the new leader.
: I am going to try and illustrate further how leader election works using the visualization on this slide <PAUSE RECORDING, run through the demo on your own before resuming recording>:
:   * Explain what the orange circles on the left are
:   * Explain what the labels S1 to S5 mean
:   * Explain what the numbers in the orange circles are
:   * Explain what the green highlight surrounding the circles is
:   * When a node sends out election requests, explain what the black dots within it mean

* Leader Election

Raft caters for, not just the happy-path, but exceptions that might occur during leader election

.image media/raft-leader-election.png

: Raft caters for not only the happy path, but also edge cases that might occur in leader election. The diagram on this slide shows the three node states and what makes a
: node transition from one of the states to another. The happy path is; that a node will start as a follower, its election timeout would expire, it would then change state
: to candidate then once it has received a majority of the votes, it changes state to leader.
: However, if for instance, a candidate does not receive a majority of the votes before its election timeout expires, it restarts the election. Another edge case is when
: a node thinks its the leader then receives a message from a leader with a higher term, it changes its state back to follower.

* Log Replication

.html raft-visualization.html

: I will now explain how log replication in Raft works.
: Log replication handles; how commands are gotten from the clients, sent to the nodes in the distributed system, and finally safely applied on their state machines.
: It is, first, important to note that the leader is the only node allowed to receive commands from clients. This means that, either the clients should be aware which node is
: the current leader, or some mechanism should be built where if any of the followers receives a command from a client they proxy this command to the leader. 
: When a command is received by the leader, the leader will first append the command into its log. The leader will then forward the command to all the other nodes in the cluster.
: It does this using what is called an AppendEntries request. The AppendEntries request contains, apart from the command, the leader's current term and meta-data of the command
: in the leader's log that appears right before the command sent in the request.
: The meta data for the previous log entry includes the index of the command in the log, and the term the command was received.
: When a follower receives an AppendEntries request from the leader, it first checks whether its safe to append the command in the request into its own log.
: Two of the checks done are; whether the follower's term is the same as the leader's term and, using the meta-data in the AppendEntries request, whether
: what the leader indicated as the command saved in its log right before the command in the request also exists in the follower's log (but as the last entry).
: If the follower is able to insert the command to its log, it does so then sends back a response to the leader indicating that it has inserted the command into its log.
: When the leader receives back a majority positive responses from followers indicating the command was successfully inserted into their logs, it applies the command into
: its state machine, marks the command as committed in its log, then sends the state machine's output back to the client.
: The next AppendEntries request the leader sends to the followers will indicate that it has applied this command into its state machine.
: It is only then that the followers will also apply the command into their state machines.
: Raft uses this approach of first confirming that a majority of the nodes have a command in their log before applying the command in the state machines so that there is a general
: consensus of what the cluster expects the state machines should look like at any particular time. This is good because if the leader were to go down, you would want a majority of the
: rest of the nodes to know what the leader had likely applied to its state machine.
: Note that the leader will send an AppendEntries request that doesn't have any command to its followers as a form of heartbeat to assure the followers that it is still alive.
: It does this whenever the distributed system hasn't received any command from its clients within a period of time. This time period is normally set to less than what is expected to be 
: the election timeout in the nodes. Raft does this to prevent followers from starting an election because they didn't receive any message from the leader before their election timeout
: expired.
: I am now going to try and illustrate how log replication works using the visualization on this slide <PAUSE RECORDING, run through the demo on your own before resuming recording>:
:   * Show which node is the current leader.
:   * Show the current term the nodes in the cluster are in.
:   * Explain that each of the nodes has its own log on the right.
:   * Explain that the commands will be appended into the logs in the order they are received, and that each command has an index in the log.
:   * Make sure to illustrate two commands being appended.

* DevOps Scenario

Rolling a software updates to servers. Expect software updates:

1. To be large (> 1GB) in some cases
2. To be regular
3. To be rolled out to servers quickly
4. To be done in a way that doesn't cause service interruption

.image media/deployment-architecture-simple.png

: So... Are there any DevOps applications for distributed consensus, apart from the more obvious ones like distributed storage?
: I'd say yes, most definitely. As an illustration I'll present common DevOps problem and show how we can use distributed consensus to deal with this problem at scale.
: Let's say you need to manage the deployment of software updates to your infrastructure. Some of the requirements that you need to consider include:
: One; the software updates might be large. In some cases larger than 1GB.
: Two; the software updates will be regular.
: Three; the software updates should be deployed to the entire infrastructure quickly.
: And four; the software updates should be done in a way that doesn't cause service interruption.
: So you, initially, go with the approach where when a software update is published in your artifacts repository, an automated pipeline kicks in and begins the
: process of deploying the software update to your servers. The deployment pipeline, currently, is targeting tens of servers spread out across a few availability zones within the same
: geographic region. The deployment pipeline rolls an update to the servers by applying the update to a small chunk of the servers at a time. It takes tens of minutes to roll an
: update to your entire infrastructure.
: There is no issue with each of the servers downloading the software updates from the centralized artifacts repository.
: Over time, however, your business grows and so does the need to have more servers in your fleet. You scale up your infrastructure to hundreds of servers spread out across different
: availability zones in different geographic regions.
: Some cracks in your deployment process begin to show:
: You notice that the artifacts repository is your biggest bottle-neck. The repository's upload link speed limits how fast the software updates can be served to servers at the same time.
: You also notice that software updates take longer to download in availability zones that are geographically further from the region your artifacts repository is deployed in.
: Another thing you notice is that since your availability zones now have more servers in them than before, the availability zones' downlinks become congested whenever the deployment pipeline
: kicks in because you now have more servers in the same availability zone trying to download the software update at the same time. Services deployed in your infrastructure experience reliability
: issues whenever a large software update is rolling because they aren't able to fetch data from clients fast enough.

* Scaled Out

Use a CDN to distribute software updates closer to availability zones

.image media/deployment-architecture-with-cdn.png

: So, you decide to scale out your software release architecture.
: The updated architecture includes a CDN node running in each of the regions your infrastructure is deployed in.
: When a software update is being rolled out to your infrastructure, the servers now download the software updates from the CDN node closest to them.
: Approach definitely works better.
: The downlinks in your availability zones, however, still get congested whenever a large software update is being deployed.
: You scale your fleet to thousands of servers. Your software update process also starts becoming more complicated. For instance, because you now have to
: deal with far more advanced adversaries, you make it a requirement that a software update's cryptographic signature has to be verified before the software update
: is applied to a server. Also, since your fleet is now composed of different kinds of servers (let's say Intel and AMD servers), you now have to confirm that an update was successfully
: deployed and is running okay for each of the kinds of servers you have deployed.
: You notice that it is harder to coordinate the deployment process, centrally, from your Continuous Delivery tool, especially in cases where a deployment check has failed for a subset
: of your infrastructure and you need to rollback to the previous release for just this subset of servers.
: It's harder because your centralized CD tool needs to get a status update from each of the thousands of servers as a deployment is running. The CD tool also has to figure out which servers
: to rollback if a certain check fails on a server. For example, if the pre-flight checks pass on your first targeted Intel server but fail on your first targeted AMD server, it is safe to assume
: that it will fail on other AMD servers, so roll back the release on just the AMD server but continue the deployment on the Intel servers. This is just one of the permutations you have to deal with.
: How can distributed consensus help scale the deployment process further?

* Distributed Deployment Process

Divide and conquer:

1. Split your fleet into homogeneous groups of servers
2. Each of the groups to coordinate deployment process independently

: Here's how I'd do it.
: I'd divide the servers into homogeneous groups. For instance, if the main distinguishing characteristics for servers in my fleet are the processor architecture and availability zone,
: then I'd have a group for each architecture in each availability zone. There would therefore be one group consisting of only Intel servers in availability zone A and another group for AMD
: servers in availability zone A. There would be a third group for Intel servers running in availability zone B and a forth group for AMD servers in availability zone B.
: Each of these groups would coordinate the deployment process independently. For the group coordination to be reliable, I'd use a distributed consensus algorithm like Raft.
: And... in order for me to use a distributed consensus algorithm like Raft to coordinate the software deployment process, I will need to represent the process as a state machine.

* Software Update as a State Machine

.image media/software-update-state-machine-diagram.png

: It turns out representing the software deployment process as a state machine isn't too hard. The state machine diagram on this slide shows a hypothetical complex deployment process that
: involves cryptographic verification of an update, then rolling the release to 1/10th of the servers in a group at a time, and running pre-flight checks after the update is applied to a server.
: If any of the steps fail, the group begins the process of rolling back to the previous software release.
: Now that the deployment process is represented as a state machine, how would the coordination actually work?
: We'd have a software coordination service running in all the servers. The service would use Raft for distributed consensus.
: The servers in a group would elect a leader. The servers would also act as both the clients and servers in the group.
: The leader, once elected, would be responsible for checking for software updates. When an update becomes available, it sends a command to the group of servers requesting for the state machine
: to change to the "Group Marked as Running Old Release" state. Once a majority of the servers in the group have this command in their log, the leader would go ahead and commit to the state by updating
: an infrastructure registry indicating that the group of servers is running an outdated version of the software.
: The leader would then issue another command to transition from the "Group Marked as Running Old Release" state to the "New Release Downloaded in Leader" state. Once there's a consensus from a
: majority of the servers that the group can transition to the state, the leader would commit to this by downloading the software update from the closest CDN node.
: At this point the leader would cryptographically check whether the software update is valid and if so would issue another command to the group requesting that the group transitions to
:  the "New Release Downloaded to the 1st 1/10th of Servers" state.
: When a consensus is reached the leader would proceed to commit to this by selecting the first 1/10th of the servers then requesting them to download the update. Once all the selected 1/10th of servers
: all confirm that they have the software update downloaded, the leader would issue a command requesting the group to transition into the next state.
: This kind of coordination would be done until a point where the group of servers is in the "Group Running Current Release" state or a rollback has been done
: and the group is back to the "Group Marked as Running Old Release" state and some form of intervention is needed.
: If ever the leader were to go down during the software update process, there would be a graceful transition to another leader since a majority of the servers are aware of the current state of the
: deployment process. The new leader would just pick up from where the old leader left off.
: So... there you have it. That's how I'd use distributed consensus to run the software update process in a massively scaled set of servers.

* github.com/jasonrogena/lightraft

.image media/lightraft-demo.gif
